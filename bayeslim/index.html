<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>The BayesLIM Project | Nicholas Kern</title> <meta name="author" content="Nicholas Kern"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="astrophysics, physics, cosmology, machine learning, AI, research, academia, radio"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nkern.github.io/bayeslim/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Nicholas </span>Kern</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/code/">code</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/posts/">posts</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">The BayesLIM Project</h1> <p class="post-description"></p> </header> <article> <p>The Bayesian Line Intensity Mapping (BayesLIM) project leverages advances in machine learning software and hardware to deliver a comprehensive Bayesian forward model for cosmological intensity mapping experiments. Its goal is to enable the first robust detection of the high redshift 21 cm signal, while faithfully accounting for covariant uncertainties between the signal and contaminants. The BayesLIM codebase is currently under development and will be released in 2024. For now, see an intial proof-of-concept (<a href="https://ml4physicalsciences.github.io/2023/files/NeurIPS_ML4PS_2023_154.pdf" target="_blank" rel="external nofollow noopener">Kern 2023</a>) presented at the NeurIPS 2023 “ML for the Physical Sciences” workshop.</p> <div class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/flowchart-min-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/flowchart-min-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/flowchart-min-1400.webp"></source> <img src="/assets/img/flowchart-min.png" class="img-fluid z-depth-0 rounded" width="700" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p class="text-left"> A flowchart describing the BayesLIM forward model. Training the model (similar to how one trains a neural network) is performed by a series of forward and backward calls to the model. We start with a (sparse) parameterization of the 21 cm sky signal, the foreground signal (diffuse and point source) the instrumental beam, and gains, and forward model them through to the interferometric visibilities (1, 2, &amp; 3). Then we compare the forward model against our raw data collected by the telescope to compute a likelihood given a noise model (4), and then incorporate any priors on our model parameters to form the posterior (4). Finally, we use automatic differentiation to rapidly compute the gradient of the posterior with respect to all of our model parameters, and use an optimization scheme to update our parameters until convergence. The shape of the posterior can then be approximated via the inverse Fisher matrix, or by using the gradient information to efficiently MCMC sample the parameter space (e.g. via HMC). </p> </div> </div> <p>Line intensity mapping (LIM)–in particular 21 cm LIM–is a theoretically powerful probe of high redshift cosmology and astrophysics. However, this technique faces the daunting challenge of mitigating astrophysical and instrumental contaminants by many orders of magnitude in order to make a robust detection of the signal. Unmodeled contaminants and uncertainties that are covariant with the signal can easily lead to false detections. Given the delicate nature of these measurements, what kind of data model and analysis pipeline is best suited to making a robust detection? Arguably, the optimal approach is to construct a joint posterior distribution across the 21 cm signal and all foreground and instrumental parameters, and to characterize the maximum a posteriori (MAP) and its shape to account for covariant uncertainties. Historically, this has been a computationally prohibitive task, forcing us to condition our data model on the assumption of a known foreground model (e.g. a known covariance), or a known instrument model. However, leveraging recent advances in machine learning software and hardware, the BayesLIM project seeks to make joint 21 cm posterior optimization possible for the first time.</p> <hr> <p>Separately, BayesLIM is a</p> <ul> <li> <p>fast and accurate forward model visibility simulator</p> </li> <li> <p>generalized direction-dependent and direction-independent calibration solver</p> </li> <li> <p>sparse signal parameterization and modeling tool</p> </li> <li> <p>constrained optimizer and MCMC sampler</p> </li> <li> <p>GPU-portable and AD-enabled data modeling tool</p> </li> </ul> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/BL_benchmark_w_grad-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/BL_benchmark_w_grad-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/BL_benchmark_w_grad-1400.webp"></source> <img src="/assets/img/BL_benchmark_w_grad.png" class="img-fluid z-depth-0 rounded" width="450" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Together, these components allow BayesLIM to jointly constrain the posterior distribution of the foregrounds, instrumental systematics, and the 21 cm signal, while making it easy to incorporate physically motivated priors in the inference process. Note that while BayesLIM is currently developed with 21 cm LIM as an application, the BayesLIM framework is equally applicable to galaxy emission-line LIM at low and high redshifts (future work).</p> <p>The BayesLIM framework is written in PyTorch, leveraging its fast automatic differentiation library and its convenient GPU-portability. This plot shows the speed-up in evaluating the forward model and computing the posterior gradients for the CPU/GPU, and with BayesLIM’s smart caching system. Together, these yield a nearly 50x speed-up in the gradient evaluation runtime relative to a standard CPU configuration.</p> <hr> <div class="text-center"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/movie_ps_beam15deg.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/movie_ps_beam15deg.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/movie_ps_beam15deg.gif-1400.webp"></source> <img src="/assets/img/movie_ps_beam15deg.gif" class="img-fluid z-depth-0 rounded" width="500" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p class="text-left"> This shows a toy-model demonstration of a BayesLIM joint foreground + instrumental parameter optimization problem. We simulate point source foregrounds with unknown amplitudes, an unknown chromatic instrumental primary beam, and optimize them jointly until an underlying EoR signal in the data is revealed (Filtered Residual). </p> </div> </div> <p>More details about BayesLIM and its development to come soon.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Nicholas Kern. Powered by Jekyll with al-folio theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>